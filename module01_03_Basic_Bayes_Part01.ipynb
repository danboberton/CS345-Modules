{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDKxiqjoHljF"
   },
   "source": [
    "# Bayesian Basics for Classification Part 1\n",
    "\n",
    "Throughout machine learning terms like probaility, a-posterior probability, likelihood and odds ratio crop up.  Actually understanding the interplayb between these related concepts can at first be difficult. Matters are not made simpler by the reality that in real-world applications information assumed by a rigorous application of these ideas lie beyond our reach.\n",
    "\n",
    "For these reasons, this notebook creates a clean closed-world exampler were all the key elements are fully defined and this toy example is then useful as a means to clarify the interlocking pieces. \n",
    "\n",
    "\n",
    "Last Update 2/08/2022\n",
    "\n",
    "**The text is released under the [CC BY-SA license](https://creativecommons.org/licenses/by-sa/4.0/), and code is released under the [MIT license](https://opensource.org/licenses/MIT).*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UQ0WZTQ8HljO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: The Binomial Distribution\n",
    "\n",
    "The binomial distribution often takes center stage in situations where there are two possible outcomes and multiple independent samples are avaialble.  The common practical introduction to binomial distributions starts with a discussion of coin tossing.  \n",
    "\n",
    "Consider tossing a fair coin 10 times. What is the probability of seeing heads exactly 5 times?\n",
    "\n",
    "To begin, here is the probability mass function for the binomial distribution which gives us the exact answer to our question.\n",
    "\n",
    "$$\n",
    "P(k ; N, p) \\; = \\:\n",
    "{{N}\\choose{k}} p^{k} ( 1 - p )^{N-k}\n",
    "$$\n",
    "\n",
    "In this equation $N$ is the total number of trials, i.e. coin tosses. The value $k$ is the number of successes, i.e. times the coins comes up heads. The value of $p$ is the probability of success, i.e. probability the coin comes up heads on single toss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def n_choose_k (n,k) :\n",
    "    res = math.factorial(n) // (math.factorial(k) * math.factorial(n-k))\n",
    "    return res\n",
    "    \n",
    "def binomial_mass_function(k, n, p) :\n",
    "    res = n_choose_k(n,k) * pow(p,k) * pow(1 - p, n - k)\n",
    "    return res\n",
    "    \n",
    "foo = binomial_mass_function(1, 10000, 1/2)\n",
    "foo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer to our question is that the probability of observing exactly $5$ heads in $10$ tosses for a fair coin is close to $25$ out of $100$ - or $0.25$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digression about Precision\n",
    "\n",
    "The following may be a bit of overkill, but binomial distributions quickly raise interesting practical questions about probabilities and calculations. With that in mind, here is a variant on the standard form given above but in such a way that Python's ability to work with very large integers and true fractions helps us avoid floating point precision questions (entirely)\n",
    "\n",
    "$$\n",
    "P(k ; N, a, b) \\; = \\: \\frac{{{N}\\choose{k}}a^{k} ( b - a )^{N-k}}{b^{N}} \n",
    "\\;\\; \\hbox{where} \n",
    "\\;\\; p = \\frac{a}{b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability is 52031268226562625 / 1246914448050473990552338851677240677389685519928870284282505593658089926888871664494997605252262162368708195588950570266972280709338361319849611620756020247365983127924612157922827909454128743470034380432387081971406788028788631542844317179130601555505655618427375578371352078615663848019342118909807024254076568540242152565422491976686590826429283635105894735976852547677305047545764283443227592261497273841185591493713177560033516738816538839208337127282847853095662696417514685587520995894790716206110829979110975385786376962999637386225461140355235142502331430342953243802154036340915659870600088427120100983411758703568461235569954862551684858479652757691376172364770343920520236829419398362679149564464258327587601512229480660878838728396395289925078053509206575464499516225737265633187053765106771300475370770010079280768031015990082052753846046184467944641019694443109094637707113762683227559849779047250650365365097879502810179188532191370039437761651392244291931285912901116059494466003441765703150375469990141368628702319878402799254556649702659271201373919212779572648547552913314611169127487713324820843353413918785198121090969265111310800686455707150223242345298031866079808620402076349962492305416300523052364876727705173448267103598296549007018399358363178850463953330748425820012350261142622856092243635283203652133497491424008133011587892717290568043157565473805163488997624110632650440270661442241814957475287712810822286450542006619581306484551463471234087149857203590955656888269434207600672092176608798454624146768656146297308622227914913867160593704938535756481335277070988575894486962388936490365458402516935261428187817057984272784411164656318803311738274342120543721302146634925440247444936613446611198571476231170508216217736450130092186385741125711816951765681614176089763786092245088603357230482850931536431562028814289380095973956758131374229741014646471184713073476462552805470385165223040552094966482523580827505903515432703396900042376704614859711025420431164765064843213185419909815672443631265424367511141995372086330151372126768922463028059688417291774356124805390102269586024618960840987587977296367356940961514108718694386654263731036353217820655888898121732172691822216763605179762522673578607736335333225699800705049541842617950081165228798034477491283412643616972344871711577898090432692993391621763563003195020147843518010564733695085521149599484776170865656935641975869714974436974884665901083519478558501945140621123124951673858272376444491415285956195984885938012489952267788453117568060014515272635860726130397313466780253663895612053367226467909777533560163876185223189300772597969533958643954376818604290660534822344094795469931199633106958605634369761332198221500483040660824347340682520636581552944613644712957753332439903880252276360231494471914986812546428354512267556467373408332529273049741786264872013664320005046426221957371759851528018657403844356555501704670098418008224671900608257192531136903487713551684361696332253950667899469480110894049537294336 - as a float 0.00000000\n"
     ]
    }
   ],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "def binomial_mass_function_rational(k, n, a, b) :\n",
    "    num = n_choose_k(n,k) * pow(a,k) * pow(b - a, n - k)\n",
    "    den = pow(b,n)\n",
    "    return Fraction(num,den)\n",
    "    \n",
    "#rat = binomial_mass_function_rational(5, 10, 1, 2)\n",
    "rat = binomial_mass_function_rational(5, 10, 1, 2)\n",
    "print(f'The probability is {rat.numerator} / {rat.denominator} - as a float {rat_float:10.8f}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far this may not to seem important, but in general realize that the probability of any particular outcome starts to become very small even for apparently simple problems.  Let us illustrate with a slight variant upon the above question.\n",
    "\n",
    "What is the probability of seeing heads only once in $100$ tosses of a fair coin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat = binomial_mass_function_rational(1, 100, 1, 2)\n",
    "rat_float = float(rat)\n",
    "print(f'The probability is {rat.numerator} / {rat.denominator} - as a float {rat_float:10.8f}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take away from this little example that just because a probability of an outcome is terribly small do not confuse it with impossible.  \n",
    "\n",
    "So for example, consider the following example where consider the set of all possible outcomes - by the way - this set of all possible outcomes it itself a KEY concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = [binomial_mass_function_rational(i,100,1,2) for i in range(101)]\n",
    "addem = foo[0]\n",
    "for i in range(1,101) :\n",
    "    addem = addem + foo[i]\n",
    "addem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And while it may not seem like a big deal - here is the equivalent calcuation using our original setup in which probabilities were returned as floating point numbers.  Close, but not identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = [binomial_mass_function(i,100,1/2) for i in range(101)]\n",
    "addem = foo[0]\n",
    "for i in range(1,101) :\n",
    "    addem = addem + foo[i]\n",
    "addem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview: Reasoning from First Principals\n",
    "\n",
    "We are about to do several things at once. \n",
    "\n",
    "From a very pragmatic side the next step is to go from our way of correctly computing the probability of $k$ heads in $n$ trials with a coin whose proability of heads on a given trial is $a$ divided by $b$.  \n",
    "\n",
    "However, we doing this as a step along the path to working out optimal deicsion rules for problems where the underlying behavior is perfectly known. In other words, we will reason from first prinicipals based upon the assumption that our task involves fair (and unfair) coins. \n",
    "\n",
    "To the pragmatic part first, you may want to go review the [binomial distribution probability mass function](https://en.wikipedia.org/wiki/Binomial_distribution). It should then become clear the code snippets below show us (in plots) the probability of different outcomes when we toss a coin $k$ times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: A Fair and an Unfair Coin \n",
    "\n",
    "Here are the probability mass functions for both a fair ($p=\\frac{1}{2}$) and an unfair ($p=\\frac{1}{5}$) coin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tosses = 10; a = 1; b = 2\n",
    "mass = np.array([float(binomial_mass_function_rational(i,tosses,a,b)) for i in range(tosses+1)])\n",
    "np.set_printoptions(precision=4)\n",
    "print(f'Probabilities for outcomes zero to n heads:\\n {mass}')\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.bar(np.arange(tosses+1),mass,color='darkgreen')\n",
    "plt.xlabel('Number of Heads',fontsize=12);\n",
    "plt.ylabel('Probability', fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the coins is not fair. In other words, it only comes up heads one out of five times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tosses = 10; a = 1; b = 5\n",
    "mass = np.array([float(binomial_mass_function_rational(i,tosses,a,b)) for i in range(tosses+1)])\n",
    "np.set_printoptions(precision=4)\n",
    "print(f'Probabilities for outcomes zero to n heads:\\n {mass}')\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.bar(np.arange(tosses+1),mass,color='darkred')\n",
    "plt.xlabel('Number of Heads',fontsize=12);\n",
    "plt.ylabel('Probability', fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: A Gambling Game\n",
    "\n",
    "At the risk of gross oversimplification, machine learning is about using data to create strategies for intelligently guessing a label or a value. While perhaps a bit simplistic, this view quickly motivates some very important concepts which includ Bayes rule, Maximum A-Posteri estimation, Maximum Likelihood and finally odds ratios.  \n",
    "\n",
    "However, let us start off with some sound commmon sense reasoning about the following game.\n",
    "\n",
    "Here is how one round of the game is played. \n",
    "\n",
    "1. I am going to pick at random either a fair coin ($p = \\frac{1}{2}$) or an unfair coind ($p = \\frac{1}{5}$. I will then proceed to toss it $10$ times and we will both observe the number of times it comes up heads ($k$ observed). \n",
    "\n",
    "2. You must guess if the coin I picked at random is fair or unfair. If you guess correctly I give you a dollar, otherwise you give me a dollar.\n",
    "\n",
    "We can play this game for as many rounds as you like - within reason and the limits of computer and simulation - and of course what matters is whether you can devise a strategy to win money."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Game Play\n",
    "\n",
    "In order to write the code to simulate game and different strategies we begin my taking advantage of the capabilities built into the NumPy random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tosses_heads (n, p) :\n",
    "    rng = np.random.default_rng()\n",
    "    cnt = np.sum(rng.random(10) > (1 - p) )\n",
    "    return cnt\n",
    "\n",
    "def trial_10_fair () : return tosses_heads(10, 1/2)\n",
    "\n",
    "def trial_10_unfair () : return tosses_heads(10, 1/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use the above to the outcomes of 100 games using only a fair coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tosses = 10; n_games = 100\n",
    "data = np.array([trial_10_fair() for i in range(n_games)])\n",
    "sumc = np.bincount(data,minlength=tosses+1)\n",
    "print(f'Game Outcomes:\\n{data}')\n",
    "print(f'Count of Outcomes:\\n{sumc}')\n",
    "print(f'Fewest and most heads seen: {np.min(data)} and {np.max(data)}')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us look at the theoretical probability mass function - curve plot - and the actual empirical results over 1000 games. \n",
    "\n",
    "As it must/should be - the empirical result is close to what we would predict. \n",
    "\n",
    "To say a bit more, the comment above about reasoning from first principals is a broad statement of our approach and it is why we can be confident our empirical observations will fall in line with our prediction - we've constructed and artificial environment/task where that must be true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Asside about Coding\n",
    "\n",
    "You see below that the two plots are sufficiently similar that a function was written to generate each - thus highlighitng what is common and making changes to each simpler. As you coding skills develop you should aspire simplify and consolidate code in this manner. However, do not confuse the final product with how it came to be. Rest assured the instructor first wrote the brute force longer version and got it working - and only then did the more consolidated version you see here get written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_plot_theory_samples (ax, tosses, n_games, mass, freq, fair_p) :\n",
    "    '''This function creates a plot where the empirical observation of number of heads \n",
    "    is shown in comparison to probability from first principals.\n",
    "    The function is designed to readily generate similar plots \n",
    "    for fair and unfair coins.'''\n",
    "    title_swap = ' Fair ' if fair_p else ' Unfair ' \n",
    "    base_color = 'darkgreen' if fair_p else 'darkred'\n",
    "    ax.scatter(np.arange(tosses+1),mass,color=base_color,marker='_',s=300.0)\n",
    "    ax.bar(np.arange(tosses+1),freq,color=base_color,alpha=0.5)\n",
    "    ax.set_title(\"{:,}\".format(n_games) + ' Games' + title_swap + 'Coin',fontsize=14)\n",
    "    ax.set_xlabel('Number of Heads',fontsize=12);\n",
    "    ax.set_ylabel('Probability / Frequency', fontsize=12);\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_games = 100; tosses = 10\n",
    "\n",
    "a = 1; b = 2\n",
    "mass = np.array([float(binomial_mass_function_rational(i,tosses,a,b)) for i in range(tosses+1)])\n",
    "data = np.array([trial_10_fair() for i in range(n_games)])\n",
    "freq = np.bincount(data,minlength=tosses+1)/n_games\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "gen_plot_theory_samples(ax[0], tosses, n_games, mass, freq, True)\n",
    "\n",
    "a = 1; b = 5\n",
    "mass = np.array([float(binomial_mass_function_rational(i,tosses,a,b)) for i in range(tosses+1)])\n",
    "data = np.array([trial_10_unfair() for i in range(n_games)])\n",
    "freq = np.bincount(data,minlength=tosses+1)/n_games\n",
    "\n",
    "gen_plot_theory_samples(ax[1], tosses, n_games, mass, freq, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play the Guessing Game\n",
    "\n",
    "Now that we have the simulations we need it is time to build the game. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player 1 - Always Fair\n",
    "\n",
    "Just to get us started, let us build a player whose strategy is to simply always guess that the coin tossed was a fair coin. How do you expect this player to do in terms of winnings. To be clear, the player wins a dollar every time they guess correctly and loose a dollar everytime they guess incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_10 (fair_p) :\n",
    "    return tosses_heads(10, 1/2 if fair_p else 1/5)\n",
    "    \n",
    "def player_1 (n_heads) :\n",
    "    '''Always choose fair coin which is signafied by returning True'''\n",
    "    return True\n",
    "\n",
    "def player_1_games (n) :\n",
    "    rng = np.random.default_rng()\n",
    "    fair = rng.random(n) > 1/2\n",
    "    outcomes = np.array([trial_10(fp) for fp in fair])\n",
    "    games = np.array([player_1(outcomes[i]) == fair[i] for i in range(n)])\n",
    "    wins   = np.sum(games)\n",
    "    losses = np.sum(~games)\n",
    "    return wins - losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_1_games(10**4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player 2 - Most Likely\n",
    "\n",
    "There is a very intuitively appealing strategy that leads nicely toward more formal decision theory. \n",
    "\n",
    "We'll get back to the more formal motivation shortly, but for now, let us just look at the probability mass functions for the fair and unfair coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tosses = 10\n",
    "mass_fair   = np.array([float(binomial_mass_function_rational(i,tosses,1,2)) for i in range(tosses+1)])\n",
    "mass_unfair = np.array([float(binomial_mass_function_rational(i,tosses,1,5)) for i in range(tosses+1)])\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.bar(np.arange(tosses+1),mass_fair,color='darkgreen',alpha=0.6)\n",
    "plt.bar(np.arange(tosses+1),mass_unfair,color='darkred',alpha=0.6)\n",
    "plt.xlabel('Number of Heads',fontsize=12);\n",
    "plt.ylabel('Probability', fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just eye ball these to histograms and keep in mind you able to see each distribution even though the overlap because of semi-transparent rendering.  The fair coin probabilities are in green, the unfair in red, and since each is partially transparent where the distributions overlap you see brown.  \n",
    "\n",
    "What should jump out is that the probability values are higher for an unfair versus a fair coin when $k$ is $0, 1, 2$ and $3$. Otherwise, the probability is higher for a fair coin.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player 2\n",
    "\n",
    "This clearly suggests a strategy; pick fair if and only if observed heads is 4 or greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_2 (n_heads, threshold=3) :\n",
    "    '''Choose fair coin over unfair iff number of heads observed is greater than 3'''\n",
    "    if (n_heads > threshold) :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def player_2_games (n, print_accuracy=False) :\n",
    "    '''This function will simulate n rounds of play for player 2. \n",
    "    The result is returned as the amount of money won by player 2. '''\n",
    "    rng = np.random.default_rng()\n",
    "    fair_true = rng.random(n) > 1/2\n",
    "    outcomes  = np.array([trial_10(fp) for fp in fair_true])\n",
    "    predicts  = np.array([player_2(outcomes[i]) for i in range(n)])\n",
    "    corrects  = fair_true == predicts\n",
    "    wins   = np.sum(corrects)\n",
    "    losses = np.sum(~corrects)\n",
    "    if print_accuracy : print(f'Accuracy of Guesses: {wins/n:5.3f}')\n",
    "    return wins - losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_2_games (10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we've done so far should make a lot of intuitive sense; guess the most likely of the two cases, i.e. fair versus not fair, based upon the relative probability conditioned upon the number of heads actually observed. If you let player 2 play more games play 2 consistently earns more money.  This was not true for player 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One More Thing - Accuracy\n",
    "\n",
    "Notice that by introducing our guessing game as a gambling excercise we side-stepped ever actually measuring the accuracy of the guesses. Let us tidy up this small omission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_2_games (10000, print_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Accuracy Follows from First Principals\n",
    "\n",
    "At this point we've shown that we can simulate game play and record and empirical estimate of how accurately Player 2 is guessing.  But because we have complete knowledge of the game we can of course go back to the original distributions and explain what we are oberving. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tosses = 10\n",
    "threshold = 3\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "mass_fair   = np.array([float(binomial_mass_function_rational(i,tosses,1,2)) for i in range(tosses+1)])\n",
    "mass_unfair = np.array([float(binomial_mass_function_rational(i,tosses,1,5)) for i in range(tosses+1)])\n",
    "\n",
    "# Note below we re-normalize so pair of distributions sum to 1.0\n",
    "mass_fair = mass_fair / 2.0\n",
    "mass_unfair = mass_unfair / 2.0\n",
    "\n",
    "fair_mislabeled   = np.zeros(tosses+1)\n",
    "unfair_mislabeled = np.zeros(tosses+1)\n",
    "for i in range(0,threshold+1) : fair_mislabeled[i] = mass_fair[i]\n",
    "for i in range(threshold+1,tosses+1) : unfair_mislabeled[i] = mass_unfair[i]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.bar(np.arange(tosses+1),mass_fair,color='darkgreen',alpha=0.6)\n",
    "plt.bar(np.arange(tosses+1),mass_unfair,color='darkred',alpha=0.6)\n",
    "plt.bar(np.arange(tosses+1),fair_mislabeled,color='orange',alpha=1.0)\n",
    "plt.bar(np.arange(tosses+1),unfair_mislabeled,color='gold',alpha=1.0)\n",
    "\n",
    "accuracy = 1.0 - np.sum(fair_mislabeled + unfair_mislabeled)\n",
    "ptitle = f'Threshold is {threshold} and expected accuracy is {accuracy:5.3f}'\n",
    "print(ptitle)\n",
    "plt.title(ptitle,fontsize=14)\n",
    "plt.xlabel('Number of Heads',fontsize=12);\n",
    "plt.ylabel('Probability Conditioned Upon Class', fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice now that you can actually see very clearly the reason for selecting the threshold which will in expectation yield the most accurate predictions. To say a bit more, Player 2 guesses incorrectly when the fair coin generates as many heads (or fewer) than the theshold (shown in orange).  Player 2 also guesses incorrectly when the unfair coin generates more heads than the threshold (shown in gold).\n",
    "\n",
    "One more important detail that foreshadows the next note book.  Note that the vertical axis probabilities are divided by two and are now described as conditioned upon whether the outcome is heads or tails. We will talk more explicitly next time about what to do when some classes arise more often in our sample than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "module01_05_matplotlib.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
